{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9ab3ffb",
   "metadata": {},
   "source": [
    "## 1. LSTM 연습코드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b29007",
   "metadata": {},
   "source": [
    "### 0_LSTM_Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "785f1618",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n",
      "--2022-05-26 10:14:19--  https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: './data/input.txt.1'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  4% 2.88M 0s\n",
      "    50K .......... .......... .......... .......... ..........  9% 34.3M 0s\n",
      "   100K .......... .......... .......... .......... .......... 13% 32.2M 0s\n",
      "   150K .......... .......... .......... .......... .......... 18% 34.3M 0s\n",
      "   200K .......... .......... .......... .......... .......... 22% 37.8M 0s\n",
      "   250K .......... .......... .......... .......... .......... 27% 36.3M 0s\n",
      "   300K .......... .......... .......... .......... .......... 32% 36.9M 0s\n",
      "   350K .......... .......... .......... .......... .......... 36% 27.4M 0s\n",
      "   400K .......... .......... .......... .......... .......... 41% 39.2M 0s\n",
      "   450K .......... .......... .......... .......... .......... 45% 38.2M 0s\n",
      "   500K .......... .......... .......... .......... .......... 50% 39.9M 0s\n",
      "   550K .......... .......... .......... .......... .......... 55% 33.2M 0s\n",
      "   600K .......... .......... .......... .......... .......... 59% 35.2M 0s\n",
      "   650K .......... .......... .......... .......... .......... 64% 34.7M 0s\n",
      "   700K .......... .......... .......... .......... .......... 68% 34.0M 0s\n",
      "   750K .......... .......... .......... .......... .......... 73% 32.1M 0s\n",
      "   800K .......... .......... .......... .......... .......... 78% 38.5M 0s\n",
      "   850K .......... .......... .......... .......... .......... 82% 39.8M 0s\n",
      "   900K .......... .......... .......... .......... .......... 87% 38.6M 0s\n",
      "   950K .......... .......... .......... .......... .......... 91% 30.4M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 96% 38.3M 0s\n",
      "  1050K .......... .......... .......... .........            100% 35.6M=0.05s\n",
      "\n",
      "2022-05-26 10:14:19 (23.3 MB/s) - './data/input.txt.1' saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm -r data\n",
    "import os \n",
    "\n",
    "try:\n",
    "    os.mkdir(\"./data\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "!wget https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt -P ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54f6d6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56839436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in c:\\users\\ghpmc\\anaconda3\\envs\\pytorch\\lib\\site-packages (1.3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a13f4a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import time, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3168f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "\n",
    "# chunk에 대한 설명은 아래 함수정의하면서 하겠습니다.\n",
    "chunk_len = 200\n",
    "\n",
    "hidden_size = 100\n",
    "batch_size = 1\n",
    "num_layers = 1\n",
    "embedding_size = 70\n",
    "lr = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5ba21a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "num_chars =  100\n"
     ]
    }
   ],
   "source": [
    "# import 했던 string에서 출력가능한 문자들을 다 불러옵니다. \n",
    "all_characters = string.printable\n",
    "\n",
    "# 출력가능한 문자들의 개수를 저장해놓습니다.\n",
    "n_characters = len(all_characters)\n",
    "print(all_characters)\n",
    "print('num_chars = ', n_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec5e029d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 1115394\n"
     ]
    }
   ],
   "source": [
    "# 앞서 다운받은 텍스트 파일을 열어줍니다.\n",
    "\n",
    "file = unidecode.unidecode(open('./data/input.txt').read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfb36c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on why the Lady Grey\n",
      "Should not become my wife and England's queen.\n",
      "And you too, Somerset and Montague,\n",
      "Speak freely what you think.\n",
      "\n",
      "CLARENCE:\n",
      "Then this is mine opinion: that King Lewis\n",
      "Becomes your e\n"
     ]
    }
   ],
   "source": [
    "# 이 함수는 텍스트 파일의 일부분을 랜덤하게 불러오는 코드입니다.\n",
    "def random_chunk():\n",
    "    # (시작지점 < 텍스트파일 전체길이 - 불러오는 텍스트의 길이)가 되도록 시작점과 끝점을 정합니다.\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a4ecda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36, 37, 38, 13, 14, 15])\n"
     ]
    }
   ],
   "source": [
    "# 문자열을 받았을때 이를 인덱스의 배열로 바꿔주는 함수입니다.\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return tensor\n",
    "\n",
    "print(char_tensor('ABCdef'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f82a489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤한 텍스트 chunk를 불러와서 이를 입력과 목표값을 바꿔주는 함수입니다.\n",
    "# 예를 들어 pytorch라는 문자열이 들어오면 입력은 pytorc / 목표값은 ytorch 가 됩니다.\n",
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d14fba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # 임베딩 함수에 대한 설명은 책과 공식 도큐먼트를 참고하시길 바랍니다.\n",
    "        # https://pytorch.org/docs/stable/nn.html?highlight=embedding#torch.nn.Embedding\n",
    "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
    "        self.rnn = nn.RNN(self.embedding_size,self.hidden_size,self.num_layers)\n",
    "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        out = self.encoder(input.view(1,-1))\n",
    "        out,hidden = self.rnn(out,hidden)\n",
    "        out = self.decoder(out.view(batch_size,-1))\n",
    "        return out,hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return hidden\n",
    "    \n",
    "model = RNN(n_characters, embedding_size, hidden_size, n_characters, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16860af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size=n_characters, \n",
    "            embedding_size=embedding_size,\n",
    "            hidden_size=hidden_size, \n",
    "            output_size=n_characters, \n",
    "            num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9cbe479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36])\n",
      "torch.Size([2, 1, 100])\n",
      "torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "# 모델 테스트 \n",
    "\n",
    "inp = char_tensor(\"A\")\n",
    "print(inp)\n",
    "hidden = model.init_hidden()\n",
    "print(hidden.size())\n",
    "out,hidden = model(inp,hidden)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7f12fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be8067dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 문자(start_str)로 시작하는 길이 200짜리 모방 글을 생성하는 코드입니다.\n",
    "def test():\n",
    "    start_str = \"b\"\n",
    "    inp = char_tensor(start_str)\n",
    "    hidden = model.init_hidden()\n",
    "    x = inp\n",
    "\n",
    "    print(start_str,end=\"\")\n",
    "    for i in range(200):\n",
    "        output,hidden = model(x,hidden)\n",
    "\n",
    "        # 여기서 max값을 사용하지 않고 multinomial을 사용하는 이유는 만약 max 값만 쓰는 경우에\n",
    "        # 생성되는 텍스트가 다 the the the the the 이런식으로 나오기 때문입니다.\n",
    "        # multinomial 함수를 통해 높은 값을 가지는 문자들중에 램덤하게 다음 글자를 뽑아내는 방식으로 자연스러운 텍스트를 생성해냅니다.\n",
    "        output_dist = output.data.view(-1).div(0.8).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        predicted_char = all_characters[top_i]\n",
    "\n",
    "        print(predicted_char,end=\"\")\n",
    "\n",
    "        x = char_tensor(predicted_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "125bbb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tensor([4.6098], grad_fn=<DivBackward0>) \n",
      "\n",
      "b1+y$/HBiZ,RshTxicC\n",
      "?E9lwoYF=\ty*[6^]%G;%GSfoI\n",
      "Yw\n",
      "]cw4SXlUe(hZ/i_=M*OIJ>f0Iz%{lk/SS]Q(7wu,f}A7/E_FnNfRL^%-d)cf]KnX/y&^x\f",
      "Z/?%XKt4/[#~-w5$\">ITv;'QG ['?01;%X\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.4747], grad_fn=<DivBackward0>) \n",
      "\n",
      "but iyald ares me yim sen fit ired orse goreiln in ry le Anre ef pimo am.\n",
      "\n",
      "U:\n",
      "Dhen it wols to bturthe to the ninge, deame yone thes be the me, the berore iren anst nomele onde, yis enrinsos fit, thin t\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.3737], grad_fn=<DivBackward0>) \n",
      "\n",
      "bkeatpee and gliss manatfy maret yhary but!\n",
      "To to speor you gafevy yof bet Tobme thelu hen thess beart hat mest fors youst:\n",
      "With they chapew in in harg mpart fors\n",
      "Astre.\n",
      "\n",
      "GIO:\n",
      "The that thet ice arves t\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.0176], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfer: thures to the sreater teaciry.\n",
      "\n",
      "WA YSot rever:\n",
      "Wave\n",
      "The be coee me toen thanspot ther,\n",
      "And sard,\n",
      "Hughing foel the.\n",
      "\n",
      "Ming, an's whunged pare; besen louls haves fery man a sor to peard berem the is\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.9715], grad_fn=<DivBackward0>) \n",
      "\n",
      "but as my heirse to brichen shale the praned sles be vereer suke bangin wath.\n",
      "I hingh's you on to deves bunon was suy heres a cime ranting,\n",
      "Wo and ganich heating calomiorne\n",
      "I seat hassel's quandest it \n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.0194], grad_fn=<DivBackward0>) \n",
      "\n",
      "bue were! as herene as thiy how sany menemcenve to the'd grecond, mine, astise, mint 'for-\n",
      "And whare the what he he's the must it the kind of whing the deave you the faetin!\n",
      "Shose thenrisee shat bure a\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.9440], grad_fn=<DivBackward0>) \n",
      "\n",
      "bune arnot your sughle igh for your sill am.\n",
      "\n",
      "Yor mes\n",
      "senter'ther, lets copead, whing's simed, stend shards,\n",
      "The hach a onow the cuar dird, I in breath.\n",
      "\n",
      "GAMEN:\n",
      "Wath dotreds.\n",
      "\n",
      "FO)nty diad,\n",
      "Giony\n",
      "And wh\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.0012], grad_fn=<DivBackward0>) \n",
      "\n",
      "belusk but In more a caretest and blood untudes lord; he wacl it a cird of Mare sins risinge, in as will and bet night it coudot lomes hape my lake seact werd Ralledan Thou the quacut these\n",
      "To Goull, m\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.9256], grad_fn=<DivBackward0>) \n",
      "\n",
      "ble.\n",
      "\n",
      "CORENVOLUCH:\n",
      "The sint fiones no this leingor to ours, And a will to his but has cailling thie pepfer on comerus ourer inesk, tarnt him.\n",
      "\n",
      "ALALIO:\n",
      "Whall I I heresone\n",
      "No mave hatk his reat mut do-bo\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.1272], grad_fn=<DivBackward0>) \n",
      "\n",
      "blese a frime the manes wat, cood you Pace, and are sume mish maby good the cobe be the dath therest the pare eller, rid at to maught do sabue in the heart your the wirt his to to list my seat il so th\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.9385], grad_fn=<DivBackward0>) \n",
      "\n",
      "bled thy tise lord will the live\n",
      "This pliens uccedous in truins to apaty your this not, no is in to dacentsoult.\n",
      "\n",
      "Shorronce mititlake cone it thou my king thing a sance.\n",
      "\n",
      "PRICA:\n",
      "My thim and sing it of \n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.8642], grad_fn=<DivBackward0>) \n",
      "\n",
      "boy.\n",
      "\n",
      "KINCENTIO:\n",
      "Youch to on she of do it.\n",
      "\n",
      "KING LORD IO:\n",
      "Whim deasse, not blood of stay prock to wn'd the tich hourbet; the hath, thy your grare, with tresacle:\n",
      "Thour sist a shou sody me a shall be st\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.7725], grad_fn=<DivBackward0>) \n",
      "\n",
      "bo,\n",
      "For tricant derse to songour lever fere he frothery be prour loot.\n",
      "\n",
      "JUBENRY:\n",
      "I lage lie she stain of liply ere lester this sheet,\n",
      "Is them ase his eed that his tor your commorburits\n",
      "Such steaithour \n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.0184], grad_fn=<DivBackward0>) \n",
      "\n",
      "by be my dome, to cout sigh the consor!\n",
      "O, come noble our within and heavers kitedly propisinish'd was day and would withous of dous my like,\n",
      "Myse and sheer I am thy charper thee heres the dray; good b\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.5339], grad_fn=<DivBackward0>) \n",
      "\n",
      "bet ip are there the scut of they, I pir with seen that love worth deant and starn yet mages frother not her sut griend apper'd shered with say hive so live you hat I will them I well, and mysersets to\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.1086], grad_fn=<DivBackward0>) \n",
      "\n",
      "buither? This pason a made,\n",
      "And promers, who sin not low usmard, you say and the sation, whose Jomen as to you was our am is love of good way;\n",
      "Well forsereming him will they is be is you.\n",
      "\n",
      "RICKANDIO:\n",
      "W\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.8455], grad_fn=<DivBackward0>) \n",
      "\n",
      "blares\n",
      "That I weach, that shase speade of of a eruiled to poor fonr\n",
      "Was'd be the work as wear\n",
      "And with fortus he deen state the ome thou sleithour mubul to save there to the bear shear felioun as like \n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.7930], grad_fn=<DivBackward0>) \n",
      "\n",
      "bus, be prose if sother a senlle him to Got blook his are all evel whoen to mer hang'd lead, O het hang broof patter-belingly sorrot\n",
      "Mantlo?\n",
      "Poor with hold lords her with uson o'lo cUne to her jay fril\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.5936], grad_fn=<DivBackward0>) \n",
      "\n",
      "ble.\n",
      "\n",
      "AUTORD:\n",
      "On the wards, shall sent as I plant thee the, to as ad.\n",
      "\n",
      "POMISTULEL:\n",
      "Heorture nends:\n",
      "Gour is the say the word:\n",
      "Whyse\n",
      "Whou all this this doth word.\n",
      "Whick as this are have to dine, band man\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.5868], grad_fn=<DivBackward0>) \n",
      "\n",
      "brince, whut I wards his with be none not sin thee steen they is is with the light roldot my lign, and be come trive fillow, but wold, my littster lies meriell. Row thee seep in my loan them, would, I \n",
      " ====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    # 랜덤한 텍스트 덩어리를 샘플링하고 이를 인덱스 텐서로 변환합니다. \n",
    "    inp,label = random_training_set()\n",
    "    hidden = model.init_hidden()\n",
    "\n",
    "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
    "    optimizer.zero_grad()\n",
    "    for j in range(chunk_len-1):\n",
    "        x  = inp[j]\n",
    "        y_ = label[j].unsqueeze(0).type(torch.LongTensor)\n",
    "        y,hidden = model(x,hidden)\n",
    "        loss += loss_func(y,y_)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
    "        test()\n",
    "        print(\"\\n\",\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deebe36",
   "metadata": {},
   "source": [
    "### 1_Char_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13361576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import time, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df1ca5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "chunk_len = 200\n",
    "hidden_size = 100\n",
    "batch_size = 1\n",
    "num_layers = 1\n",
    "embedding_size = 70\n",
    "lr = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08a31a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "num_chars =  100\n"
     ]
    }
   ],
   "source": [
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "print(all_characters)\n",
    "print('num_chars = ', n_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "937f88aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 1115394\n"
     ]
    }
   ],
   "source": [
    "file = unidecode.unidecode(open('./data/input.txt').read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63445555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y hold with her, but never lutes.\n",
      "\n",
      "BAPTISTA:\n",
      "Why, then thou canst not break her to the lute?\n",
      "\n",
      "HORTENSIO:\n",
      "Why, no; for she hath broke the lute to me.\n",
      "I did but tell her she mistook her frets,\n",
      "And bow'd \n"
     ]
    }
   ],
   "source": [
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed866a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36, 37, 38, 13, 14, 15])\n"
     ]
    }
   ],
   "source": [
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return tensor\n",
    "\n",
    "print(char_tensor('ABCdef'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d417764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "413f0bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
    "        self.rnn = nn.GRU(self.embedding_size,self.hidden_size,self.num_layers)\n",
    "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        out = self.encoder(input.view(1,-1))\n",
    "        out,hidden = self.rnn(out,hidden)\n",
    "        out = self.decoder(out.view(batch_size,-1))\n",
    "        return out,hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return hidden\n",
    "    \n",
    "model = RNN(n_characters, embedding_size, hidden_size, n_characters, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fbcd6f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36])\n",
      "torch.Size([1, 1, 100])\n",
      "torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "inp = char_tensor(\"A\")\n",
    "print(inp)\n",
    "hidden = model.init_hidden()\n",
    "print(hidden.size())\n",
    "\n",
    "out,hidden = model(inp,hidden)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e9326f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f843e3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    start_str = \"b\"\n",
    "    inp = char_tensor(start_str)\n",
    "    hidden = model.init_hidden()\n",
    "    x = inp\n",
    "\n",
    "    print(start_str,end=\"\")\n",
    "    for i in range(200):\n",
    "        output,hidden = model(x,hidden)\n",
    "\n",
    "        output_dist = output.data.view(-1).div(0.8).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        predicted_char = all_characters[top_i]\n",
    "\n",
    "        print(predicted_char,end=\"\")\n",
    "\n",
    "        x = char_tensor(predicted_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4bbd4887",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tensor([4.5984], grad_fn=<DivBackward0>) \n",
      "\n",
      "b!3V4RX7M[IOO^$lj\t\t7ViDg?EZDw8%*N \"\n",
      "B\u000b",
      "ahoRI!}OU$)SL+nR~P\u000b",
      "9WPMKRK,8CE$OB};dyppus`2\n",
      "\\T;0N%~)XB\t9%^%\n",
      "5I<W0r|LRu<qaKc Nh}Cx\"Ow$O6^\u000b",
      "|]TE}j2KY#z4P7,pg[`E_]wU^Q#~,[!e'lj1fi[;dP\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.4873], grad_fn=<DivBackward0>) \n",
      "\n",
      "b\n",
      "GEL::\n",
      "Wos.\n",
      "USNTIA Ilbn th inomd.\n",
      "AiRWVhin.\n",
      "\n",
      "CdEet coume ol he fmeves mo.\n",
      "\n",
      "PAATI imer melim hattt,\n",
      "Ger, the beeveer.\n",
      "\n",
      "O histend hek lon nd arcet thor con the wI brat;\n",
      "Thend,\n",
      "I rwire onend ane sisel th\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.2573], grad_fn=<DivBackward0>) \n",
      "\n",
      "br bis lith hione semeeg the doe ime hound andither cord whet the'd boung\n",
      "Sur worras you an the halighh yind, thoubus lot med begthes h kow males.\n",
      "\n",
      "\n",
      "POUWEs:\n",
      "And aans thee to the miangresald ing\n",
      "Wnow th\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.1600], grad_fn=<DivBackward0>) \n",
      "\n",
      "bJnd.\n",
      "\n",
      "GRNTINO:\n",
      "And a tor I aiulas a wor fatr ar and yough sancut ors sleant thith sone ill I thome to wapear gast the soud is heat eses, ant ber moun afd thente our yous kat datt somt wat in wir stou \n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.2131], grad_fn=<DivBackward0>) \n",
      "\n",
      "bch nolkser\n",
      "The hand cace to in bul the cronghoflle thou hast shroul mare sellf and what be at wecliat,\n",
      "ThiclerS for fhain, a here for to and bes; arn cave that and fore\n",
      "Whis selh oul ull: to the all, \n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.0762], grad_fn=<DivBackward0>) \n",
      "\n",
      "bRat enene,\n",
      "I wicersime whear our were do to sire then whas sakied home coonss, mepie hend or in fipt versenbor the my faticigu lorg; the buch tat to blen in you gretinging what with my the what store \n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.8790], grad_fn=<DivBackward0>) \n",
      "\n",
      "be his rord reted gotise soths?\n",
      "With have to wice ig the with he dome there to now dis his ly his to thou deank the mire comeenly all that lerves\n",
      "And you dicmen the duint tharied by life me my gose, sh\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.9809], grad_fn=<DivBackward0>) \n",
      "\n",
      "beat arm hernceshin tir pore for pear wulf whe wolrire of yat wour but grear stread in diss;\n",
      "Aweser,\n",
      "wenler spuom,\n",
      "The cangen will love to wore me can an ou would wenter ming thy awunter your me is bur\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.8620], grad_fn=<DivBackward0>) \n",
      "\n",
      "ble ppour here quress a mome\n",
      "That you and the well thour I the with ap shals bey fimess may his me be bester efing?\n",
      "\n",
      "PCAUTIUS:\n",
      "Who, of have frather my my dealt him the hath hown his my hire my the piol\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.8656], grad_fn=<DivBackward0>) \n",
      "\n",
      "burse and may mespelly the us my meen what baty slate of for I a greake.\n",
      "For hads, am?\n",
      "In hand thou mosss?\n",
      "Whe\n",
      "shong your well to Loud and so kissunser, ereing what woun of nocess nom the Freness maran\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.8670], grad_fn=<DivBackward0>) \n",
      "\n",
      "bilg of will on theoth.\n",
      "\n",
      "Marnot and plaingy and sooth and Will we santge.\n",
      "\n",
      "ETRUCHINGEN,\n",
      "Shat sperst shey since with put to her cared's what is live,\n",
      "And thy leld unsigues more sond the gandering reance\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.8012], grad_fn=<DivBackward0>) \n",
      "\n",
      "bun are that make speate this be dother sumppace his day bertied; sure, is priest burd,\n",
      "The lay:\n",
      "It to have the it not his shall what the be mostermess and of courd; I dowstay lemsely tay promings, tha\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.7489], grad_fn=<DivBackward0>) \n",
      "\n",
      "but you. an shall lord.\n",
      "\n",
      "GLOMELUS:\n",
      "Whis son is binest, he love my deople you the can a is be the thain;\n",
      "As a gusest shou sellanvest tier erece,\n",
      "Sust we'll to stands and shoughen souble not shat, I this\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.8487], grad_fn=<DivBackward0>) \n",
      "\n",
      "blough thou dacied knorth not her for his mer you all till with porely not ip they you him at he detood them 'ting I did his boer! Your grad deating in is stone yet hom he donour, my efurited and the m\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.6565], grad_fn=<DivBackward0>) \n",
      "\n",
      "brents\n",
      "Thour hentle not my prokis and Clolfalt, and whatth from to here wand for thy peepnis to but a pristuness's for the resfert\n",
      "To net nesser: to though for he graite.\n",
      "\n",
      "JOLAUS:\n",
      "A hond feers our his \n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.6656], grad_fn=<DivBackward0>) \n",
      "\n",
      "by to now; in him. look to triat to not;\n",
      "Can's the porfulst lem for in him one the quep but my alest a pustacte compows and now spiely but our dosess of I will this should be more, you Pramion deasely \n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.8852], grad_fn=<DivBackward0>) \n",
      "\n",
      "blesuran\n",
      "To cond and this but to thour, but a main anist fart am,\n",
      "Coward the muscreat my meats?\n",
      "Of the ir trother these eardon thy will was and a neepioly of my cilaciy, for for such as is our dost,\n",
      "A \n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.8749], grad_fn=<DivBackward0>) \n",
      "\n",
      "bet of to bay, is may see, the thee, me on this old with thy good, one the prosty turmes of chant,\n",
      "Shit to him tome; the peeving art our do?\n",
      "\n",
      "PETROM:\n",
      "O so thother, thou makes, methen exestrace?\n",
      "\n",
      "GOLAUS\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.7785], grad_fn=<DivBackward0>) \n",
      "\n",
      "bour brord, siglings the play, and to mans, there!\n",
      "\n",
      "GELOUS:\n",
      "The grave tand, with that were so would not the vear it pose. O, and to my dains,\n",
      "I swee to great amanding,\n",
      "Deat he alf had the come it dead,\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.8179], grad_fn=<DivBackward0>) \n",
      "\n",
      "bBy desear, ware the sage and man you he wiall she fair.\n",
      "\n",
      "PRICA:\n",
      "Hare me do this name; you there known with to do againice's wich onied to\n",
      "feath again in the empt to shouls,\n",
      "And fear to mark the pears \n",
      " ====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    inp,label = random_training_set()\n",
    "    hidden = model.init_hidden()\n",
    "\n",
    "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
    "    optimizer.zero_grad()\n",
    "    for j in range(chunk_len-1):\n",
    "        x  = inp[j]\n",
    "        y_ = label[j].unsqueeze(0).type(torch.LongTensor)\n",
    "        y,hidden = model(x,hidden)\n",
    "        loss += loss_func(y,y_)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
    "        test()\n",
    "        print(\"\\n\",\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4293fbd",
   "metadata": {},
   "source": [
    "### 2_Char_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "088e2351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import time, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a99fef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "chunk_len = 200\n",
    "hidden_size = 100\n",
    "batch_size = 1\n",
    "num_layers = 1\n",
    "embedding_size = 70\n",
    "lr = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b5c3fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "num_chars =  100\n"
     ]
    }
   ],
   "source": [
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "print(all_characters)\n",
    "print('num_chars = ', n_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e93a38f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 1115394\n"
     ]
    }
   ],
   "source": [
    "file = unidecode.unidecode(open('./data/input.txt').read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75bb03b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that a winged Mercury did bear:\n",
      "Some tardy cripple bore the countermand,\n",
      "That came too lag to see him buried.\n",
      "God grant that some, less noble and less loyal,\n",
      "Nearer in bloody thoughts, but not in blood\n"
     ]
    }
   ],
   "source": [
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9faca1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36, 37, 38, 13, 14, 15])\n"
     ]
    }
   ],
   "source": [
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return tensor\n",
    "\n",
    "print(char_tensor('ABCdef'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "292a8fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "36b3d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
    "        self.rnn = nn.LSTM(self.embedding_size,self.hidden_size,self.num_layers)\n",
    "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, input, hidden, cell):\n",
    "        out = self.encoder(input.view(1,-1))\n",
    "        out,(hidden,cell) = self.rnn(out,(hidden,cell))\n",
    "        out = self.decoder(out.view(batch_size,-1))\n",
    "        return out,hidden,cell\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(self.num_layers,batch_size,self.hidden_size)\n",
    "        cell = torch.zeros(self.num_layers,batch_size,self.hidden_size)\n",
    "        return hidden,cell\n",
    "    \n",
    "\n",
    "model = RNN(n_characters, embedding_size, hidden_size, n_characters, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4cb94cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36])\n",
      "torch.Size([1, 1, 100])\n",
      "torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "inp = char_tensor(\"A\")\n",
    "print(inp)\n",
    "hidden,cell = model.init_hidden()\n",
    "print(hidden.size())\n",
    "\n",
    "out,hidden,cell = model(inp,hidden,cell)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "49bb8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5023610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    start_str = \"b\"\n",
    "    inp = char_tensor(start_str)\n",
    "    hidden,cell = model.init_hidden()\n",
    "    x = inp\n",
    "\n",
    "    print(start_str,end=\"\")\n",
    "    for i in range(200):\n",
    "        output,hidden,cell = model(x,hidden,cell)\n",
    "\n",
    "        output_dist = output.data.view(-1).div(0.8).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        predicted_char = all_characters[top_i]\n",
    "\n",
    "        print(predicted_char,end=\"\")\n",
    "\n",
    "        x = char_tensor(predicted_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "27141511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tensor([4.5823], grad_fn=<DivBackward0>) \n",
      "\n",
      "K1P:Yc&I2#3yMJ7Ug'UL>hCb>!@ST+2\t{Y@F7ep>\u000b",
      "z9BOz$ad=d 6MPnvvnOtr&dsf\n",
      "\n",
      "\n",
      "\n",
      " tensor([2.5347], grad_fn=<DivBackward0>) \n",
      "\n",
      "bthith bert no sorind, t mer aalllt, mel thenp ont thid gIllalt nopy he\n",
      "RAweign hat meo siin\n",
      "T-low sourrn anur wais tuage me favet this howt yhis sit thimet hane ir maUls oum hibur pooms whcanes hithom\n",
      "\n",
      "\n",
      "\n",
      " tensor([2.3985], grad_fn=<DivBackward0>) \n",
      "\n",
      "bDzWHour aisusts henf pond gin hhighau mat oule wiord sroporinge hamesis hatre hing seners, o thard hino foSes or vod aro, nith theer on,  dhey wous allsur cpeanbes belly sot are irs tins the nat, yout\n",
      "\n",
      "\n",
      "\n",
      " tensor([2.1899], grad_fn=<DivBackward0>) \n",
      "\n",
      "bf me thing and,\n",
      "Whe ondw she ye or fot we:inon thererd angrep in mey theant tou ungearn\n",
      "\n",
      "EYO:\n",
      "Whan wibos th in be?\n",
      "SI the swich I whate oof orvins faing so met andare, we ad wito winkine the, wod worn\n",
      "\n",
      "\n",
      "\n",
      " tensor([2.2640], grad_fn=<DivBackward0>) \n",
      "\n",
      "brous to of than think theat an elald wat est you preashy chat.\n",
      "\n",
      "PENTIS:\n",
      "If he leat and but\n",
      "A mat all to mar, mady the you kan thos thou cod you an fere lour ndot whe.\n",
      "\n",
      "DUIO:\n",
      "\n",
      "PoUD do my and here sat d\n",
      "\n",
      "\n",
      "\n",
      " tensor([2.1580], grad_fn=<DivBackward0>) \n",
      "\n",
      "bbs;S:\n",
      "And hame Prole gfor gose lomewn hat youn's, whe?\n",
      "\n",
      "WAOLT:\n",
      "I slevar and lives lard in the the the pow I molle that and ill he the sod in doven ir the saest te youltel noth wigh in ser thou the sou\n",
      "\n",
      "\n",
      "\n",
      " tensor([2.1157], grad_fn=<DivBackward0>) \n",
      "\n",
      "by !uptche thow thood frare, Gathen, greast sing thate; mis the nhat his ming sor sho ding in the the, the sot thean weven.\n",
      "\n",
      "Swirs where the ant bevir ence therers, the fent:\n",
      "And wtoring lonee; I domo \n",
      "\n",
      "\n",
      "\n",
      " tensor([2.1009], grad_fn=<DivBackward0>) \n",
      "\n",
      "by and sich sall as, wing heay santh. Jlripe's me coustich hiss,'d: he will shes is math with i't to not,\n",
      "Do date and, Cass thell elt ae, than sterbioveen\n",
      "And be.\n",
      "\n",
      "CRMING Vhore whe trone.\n",
      "\n",
      "nom\n",
      "To parth\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.9461], grad_fn=<DivBackward0>) \n",
      "\n",
      "bone and gratent by chave cave be coveet hilly bather.\n",
      "\n",
      "But to of bot be to woll googh of for bune.\n",
      "\n",
      "ING BRES:\n",
      "Fer wo mand it gour ans wimt be wills hearing\n",
      "Fing I kpear hill thee,\n",
      "What me goon.\n",
      "\n",
      "QUENR\n",
      "\n",
      "\n",
      "\n",
      " tensor([2.2023], grad_fn=<DivBackward0>) \n",
      "\n",
      "be itmoul to be be manes;\n",
      "Ains, your Ley to de laytore Freves am the broun the thouse: the stow\n",
      "What de knour wat than krare, and sick Noster we badull and with me not to the sing is doe\n",
      "That with not \n",
      "\n",
      "\n",
      "\n",
      " tensor([2.0183], grad_fn=<DivBackward0>) \n",
      "\n",
      "bange aud but ould you, bust ougeld it prade this aid.\n",
      "\n",
      "LOSTENCED TIHA:\n",
      "Ay renered as dath hall this in he Maur that be my iconge the denous I the your hat htes\n",
      "As thich agary.\n",
      "\n",
      "MARINGSTHARD II:\n",
      "Thy te\n",
      "\n",
      "\n",
      "\n",
      " tensor([2.0130], grad_fn=<DivBackward0>) \n",
      "\n",
      "bies.\n",
      "So corder not Coves I fosh,\n",
      "But the sthan how hand that mants he come in not marthous,\n",
      "Therees.\n",
      "\n",
      "Fist beancen\n",
      "Withes for all the were os pririon:\n",
      "And sto'd the thour mustarught have bese\n",
      "not beas\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.9518], grad_fn=<DivBackward0>) \n",
      "\n",
      "brous ond.\n",
      "\n",
      "ANCINGABE:\n",
      "Thit is ene prouck whee ance is the that, fold; and be to what comperst, be hadd yous Jone coman in the pouster fire the pale our quen in wish and nill.\n",
      "\n",
      "VOLOMIN:\n",
      "So that I lood\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.8904], grad_fn=<DivBackward0>) \n",
      "\n",
      "bews the liteghy in the broo's thoul hand be mains;\n",
      "Band and becime dor\n",
      "Yor to desers ere the his and you pued to say plake the Tedour cloth, not und;\n",
      "And onrood for mave Raingeert mankfine.\n",
      "\n",
      "MATIAT:\n",
      "N\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.9919], grad_fn=<DivBackward0>) \n",
      "\n",
      "bentrack in it ing.\n",
      "\n",
      "Son:\n",
      "I fult son soult,\n",
      "For your wimpel.\n",
      "\n",
      "BEPM:\n",
      "Phat my vidsent\n",
      "Leptle with storsectest hay, a ance.\n",
      "\n",
      "Firing Ist theeran:\n",
      "But 'Acomest the chath my rovef appare!\n",
      "Thy sich and be mor\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.6778], grad_fn=<DivBackward0>) \n",
      "\n",
      "by seesectert be seeed, and the hath with: ore.\n",
      "\n",
      "GLOUCESTERES:\n",
      "I'g bo inourt of mands she to greile breader,\n",
      "For faribed an the more, Menwillet:\n",
      "Bot shosen\n",
      "And sweps to how wotle, and whee have gradein\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.8193], grad_fn=<DivBackward0>) \n",
      "\n",
      "beck and and I chone are thy repiowiny to the ir just to the werd erese the with is pellast me me vith then knard!\n",
      "\n",
      "VOMIANUS:\n",
      "The howa the for our weelbuseance\n",
      "Nay marned shopon\n",
      "leapter herver that vay\n",
      "\n",
      "\n",
      "\n",
      " tensor([2.1477], grad_fn=<DivBackward0>) \n",
      "\n",
      "ble\n",
      "Wile tian holl work, and heed\n",
      "That got to the plamy his come noo sall and he preinion this bay seep the to pay, he be that a but here will the' the howblost to leer pay,\n",
      "And the I man list not ento\n",
      "\n",
      "\n",
      "\n",
      " tensor([2.0279], grad_fn=<DivBackward0>) \n",
      "\n",
      "buws on., what swot\n",
      "Now duste all a huret shour coopseles, strave of in you kinds sourd.\n",
      "\n",
      "Thirse: I thou of shave partuer\n",
      "Take you, that me geather me and the his bride forson arder for the seath of Go\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.7718], grad_fn=<DivBackward0>) \n",
      "\n",
      "be there countses you thout grest\n",
      "Or a for a no sight ank of thy revife griff the the compash as and sows,\n",
      "Whiep, this unday's that that,\n",
      "To why the now hous.\n",
      "\n",
      "CORIOLANUS:\n",
      "What how one, my good so bese\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    inp,label = random_training_set()\n",
    "    hidden,cell = model.init_hidden()\n",
    "\n",
    "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
    "    optimizer.zero_grad()\n",
    "    for j in range(chunk_len-1):\n",
    "        x  = inp[j]\n",
    "        y_ = label[j].unsqueeze(0).type(torch.LongTensor)\n",
    "        y,hidden,cell = model(x,hidden,cell)\n",
    "        loss += loss_func(y,y_)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
    "        test()\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38b94b8",
   "metadata": {},
   "source": [
    "## 2. linux.txt를 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b2430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r data\n",
    "import os \n",
    "\n",
    "try:\n",
    "    os.mkdir(\"./data\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "!wget https://raw.githubusercontent.com/GunhoChoi/PyTorch-FastCampus/master/05_RNN/2_Char_RNN/data/linux.txt -P ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "52aab196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import time, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d4e511a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "chunk_len = 200\n",
    "hidden_size = 100\n",
    "batch_size = 1\n",
    "num_layers = 1\n",
    "embedding_size = 70\n",
    "lr = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "209f9b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "num_chars =  100\n"
     ]
    }
   ],
   "source": [
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "print(all_characters)\n",
    "print('num_chars = ', n_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feede38f",
   "metadata": {},
   "source": [
    "#### linux.txt 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e882657e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 33756\n"
     ]
    }
   ],
   "source": [
    "file = unidecode.unidecode(open('./data/linux.txt').read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8c79b4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y, false);\n",
      "}\n",
      "\n",
      "/**\n",
      " * bfq_reparent_leaf_entity - move leaf entity to the root_group.\n",
      " * @bfqd: the device data structure with the root group.\n",
      " * @entity: the entity to move.\n",
      " */\n",
      "static void bfq_reparent\n"
     ]
    }
   ],
   "source": [
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())\n",
    "\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return tensor\n",
    "\n",
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b7d383b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
    "        self.rnn = nn.LSTM(self.embedding_size,self.hidden_size,self.num_layers)\n",
    "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, input, hidden, cell):\n",
    "        out = self.encoder(input.view(1,-1))\n",
    "        out,(hidden,cell) = self.rnn(out,(hidden,cell))\n",
    "        out = self.decoder(out.view(batch_size,-1))\n",
    "        return out,hidden,cell\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(self.num_layers,batch_size,self.hidden_size)\n",
    "        cell = torch.zeros(self.num_layers,batch_size,self.hidden_size)\n",
    "        return hidden,cell\n",
    "    \n",
    "\n",
    "model = RNN(n_characters, embedding_size, hidden_size, n_characters, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6d9023ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36])\n",
      "torch.Size([1, 1, 100])\n",
      "torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "inp = char_tensor(\"A\")\n",
    "print(inp)\n",
    "hidden,cell = model.init_hidden()\n",
    "print(hidden.size())\n",
    "\n",
    "out,hidden,cell = model(inp,hidden,cell)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "39e8a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5ab64fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    start_str = \"b\" # b로 시작하는 문장 예측\n",
    "    inp = char_tensor(start_str)\n",
    "    hidden,cell = model.init_hidden()\n",
    "    x = inp\n",
    "\n",
    "    print(start_str,end=\"\")\n",
    "    for i in range(200):\n",
    "        output,hidden,cell = model(x,hidden,cell)\n",
    "\n",
    "        output_dist = output.data.view(-1).div(0.8).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        predicted_char = all_characters[top_i]\n",
    "\n",
    "        print(predicted_char,end=\"\")\n",
    "\n",
    "        x = char_tensor(predicted_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "be737735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tensor([4.5909], grad_fn=<DivBackward0>) \n",
      "\n",
      "!e^03/eaM)SXGERVm_DLSdvqd0h!Mm6bUH>TpCh,`L,S&x\"\u000b",
      "]wVA:Y~WxC7?)6gg=%J8cu;`Gke&A|&^g S5lDIq9?G#8klprZ%0hsGY!Jir?f<B&*:X'RsmQ:&cV q5pI`7((jvn'E,bA/mv5?|7KlfOwriwp,w&s[sQ\u000b",
      "L|^cLA+E]2H|&Q|;|v\n",
      "<+\n",
      "\n",
      "\n",
      "\n",
      " tensor([2.5844], grad_fn=<DivBackward0>) \n",
      "\n",
      "bst&ue he * bfq_gsfonw,\n",
      "\t\t\t\t\t\tG\n",
      "\n",
      " bfqg_erhenr bfqg-strut * *ouc f)\n",
      "oi sinncre nit bfqggb(nd bfqgrdse bfqg_grchgsroeenitiie bflkg_atry  G bsfqg stw_ifo_po\td (onita_s uc upitcs m\n",
      "\tObfqggstr eeato_\n",
      "\t\t\t\t}l\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.8536], grad_fn=<DivBackward0>) \n",
      "\n",
      "berint * B phe = on  bfqg, the porsp tiv bfq_eaoging);\n",
      "}\n",
      "\n",
      "\t * blkg rour *bfqg_stat_alseressup * blkerechct_e f\n",
      ".\n",
      "he flde group bfqg_prwup(/en canene c\n",
      "\trenit stathg ifllree if gse)\n",
      "\t\t *\n",
      "\trinbfqucuse);\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.9721], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfqq_group *sate bfq_deice with stats ont it_bfq_group_smwaree, blkg = bfqd = bfqgs)\n",
      "\t\tint_rit)\n",
      "\t\t\t\t\t * bfqg_stat,;\n",
      "\tif the sintitats = blkg bfqg group = bfqq_pariced_alkn\te_stat_red(ine iond bfq_dele \n",
      "\n",
      "\n",
      "\n",
      " tensor([1.4057], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfqg);\n",
      "\tstruct ats bfqg(;\n",
      "upqueue = bfqg_stats_bfqd->ste = bfq_antind,  fh\n",
      "\t\t * neat_rerentiting->docis);\n",
      "}\n",
      "\n",
      "/*\n",
      "\t\t\t\t *hse)\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t *  of (&thame);\n",
      "\n",
      "\tif (bfq, bfqg->queed_blkg_cd_ong,que cioc *bus\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.3134], grad_fn=<DivBackward0>) \n",
      "\n",
      "blkg_poig_stats_statite = bfq_date_and, fole, stats_pig_time(strup_servue_seq_tame);\n",
      "\tbfqg_stat_add_theed itse in(bfqd->emptity->aretseus wata sf)e\n",
      "\t\t. * bfq(bfqg_pdate_fin(s->sthed_witity.ne);\n",
      "}\n",
      "\n",
      "\tblk\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.2066], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfqd(&stats_sue(stat_sdive_(blkg(stat)\n",
      "{\n",
      "\teto_seque *bic_cls_bicg_print_stats);\n",
      "\tist blkg_stats->nemp#\"AOFQG, PULLLL;\n",
      "\tif (bfqq.(egroup *nats = &bfqg=, &group *bfqg->sfta(nets->voic_serd_lopinting(stat\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.3559], grad_fn=<DivBackward0>) \n",
      "\n",
      "blkg_priaserstrvic_bfqg)) In\n",
      "\tblkg_policy_bfq_medut(&stats->entity->group, struct bfq_queue_iddlerent = bfq_dataite_bfqq, &stats->sats, 0;\n",
      "\t\tretuch service_ursime)e, group. stats = 1f thed = bfqg_grup \n",
      "\n",
      "\n",
      "\n",
      " tensor([1.4063], grad_fn=<DivBackward0>) \n",
      "\n",
      "bing_meq_blkg_polic_wait_repdate *ef4,\n",
      "\n",
      "\t\t\t\t    sthtineg)\n",
      "{\n",
      "\tstruct bfq_des_wait_rmenty.p,\n",
      "\t\t\\\n",
      "\t\t\t\t\t\t\t\tbfqg_to_blkcg_prinpude);\n",
      "\n",
      "\t\tfremptive,\n",
      "\t\t.   illingrel moved);\n",
      "\tblkg_stat_idile_ix(af(state *struc\n",
      "\n",
      "\n",
      "\n",
      " tensor([0.8939], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfqc->eentity(struct bfqg_stat_sed_time);\n",
      "}\n",
      "\n",
      "void blkg_rwstats->start_idLio_core_time);\n",
      "\trstruct bfq_group (&stats->avg_stat_eq_exit_time_time);\n",
      "\t\tbfqg(bfqg_print_blkcg(bfqq_policy_group *bfqg the blkg\n",
      "\n",
      "\n",
      "\n",
      " tensor([0.5425], grad_fn=<DivBackward0>) \n",
      "\n",
      "blkcg_prfilsicy_datats);\n",
      "\treturn NULL;\n",
      "\n",
      "\tif (!bfqg_to_blkg_print_blkg(strucu ser_cgrouct gfp) {\n",
      "\t\tif (bfqq);\n",
      "\tbfqd);\n",
      "\n",
      "\t\t\t\t\t * the bfqg onsis at static of the orecuns its by concighy int colaym - seq_gr\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.0398], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfqg->stats *pd, pd, 1);\n",
      "\t}\n",
      "\n",
      "\treturn bfqg_prio_set_rewtitinn;\n",
      "\tbfqg_stat_add(&stats->queued)) { BFQG_FF+G_meche_wioup.iwe(bfqg(bfqg_prfills, wstruct blkg_stats_clecurio_data, &bfqg->pd((struct bfq_pd_t\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.4290], grad_fn=<DivBackward0>) \n",
      "\n",
      "blkg_bfqg_not_queue_suxize_set_to_entity_u64(bfqg_stat_exientitivate\",\n",
      "\t\t\t\t\t\t\t\t\t   bfqg_stats_wait(&stats->dequeue) ||\n",
      "\t        bfq_group *bfqq, gfp))\n",
      "\tbfqg_stat_add, &bfqg->stats->stars_wait_inits(bfq\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.3907], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfqg->bfqg_print_rwstat_restrues((bfqg_stat_exit(&stats->weight,\t\t.name = bfqg->prio_t(bfqg_prfill_ec_start_sectorssta *bfqd, gfp) {\n",
      "\t\t\t   struct bfq_sorice_tove_sy(struct bfq_group *bfqd, bfqg)\n",
      "{\n",
      "\tstr\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.4710], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfqg, blkcg__prio_bfqq(unsize_samples);\n",
      "}\n",
      "\n",
      "struct bfqg_stats_class);\n",
      "}\n",
      "\n",
      "/\n",
      "\tif (blkg_print_stat_age_show(bic_to_bfqq(bic, sur);\n",
      "}\n",
      "\n",
      "\n",
      "static struct bfq_group *bfqg)\n",
      "{\n",
      "\tstruct bfqg_stats_update_cion_cftrop\n",
      "\n",
      "\n",
      "\n",
      " tensor([0.4907], grad_fn=<DivBackward0>) \n",
      "\n",
      "bic_bfqg)\n",
      "{\n",
      "\tstruct bfq_group *bfqg = pd_fvit(&stats->mervice(struct bfq_group *bfqg)\n",
      "\n",
      "\tstruct bfq_group *bfqg *beay eata service to inblkg and the longing the root\n",
      "\t\t\t  (is no the and\n",
      "\t * in loss in b\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.4506], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfq_chgroup_wait_rev(r;\n",
      "\n",
      "\tbfqg_print_rwstat_recursive,\n",
      "\t\t.private = u64\n",
      "\t\trestating = cpurstave_cqueue (intues)\n",
      "{\n",
      "\tblkg_rwstat_su_state_service(bfq_bq_bfq_queue *pd_time(struct bfq_group_data *bfqd, st\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.5063], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfqg);\n",
      "\n",
      "#i/\n",
      "\n",
      " */\n",
      "#include flule = offters = bfqg_print_stat_exit(&stats_entity.new_weight_weight_time),\n",
      "\t\t.prity;\n",
      "\n",
      "\tbfq_cpd_async_bfqq, stats_fin_red_bfqq_entity.\n",
      "\t *\n",
      "\t * @bfqd:\n",
      " * blkg_stats_recursive\n",
      "\n",
      "\n",
      "\n",
      " tensor([0.4874], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfqg);\n",
      "\tsfils.service_time(bfqg);\n",
      "\n",
      "\tstruct bfq_group *bfqg = prinat, &bfqg->start_time);\n",
      "\n",
      "\tblkg_stats_setingst_group *bfqg)\n",
      "{\n",
      "\tblkg_to_bfqd, &bfqg->sched_datarent;\n",
      "\n",
      "\treturn NULL;\n",
      "\n",
      "\treturn blkg->res_tim\n",
      "\n",
      "\n",
      "\n",
      " tensor([0.6316], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfqd->root_tree(struct bfq_group *bfqg, unsigned thetle hopdholove\n",
      "\t * (struct bfq_group *bfqq_group (in theed blkcg thesed whate lkstruct bfq_ewsity(struct sched_data *pd)\n",
      "{\n",
      "\tstruct bfq_group * NTY\n",
      "\ts\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    inp,label = random_training_set()\n",
    "    hidden,cell = model.init_hidden()\n",
    "\n",
    "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
    "    optimizer.zero_grad()\n",
    "    for j in range(chunk_len-1):\n",
    "        x  = inp[j]\n",
    "        y_ = label[j].unsqueeze(0).type(torch.LongTensor)\n",
    "        y,hidden,cell = model(x,hidden,cell)\n",
    "        loss += loss_func(y,y_)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
    "        test()\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea4ddf",
   "metadata": {},
   "source": [
    "## 3. \"u\"라는 문자로 understand with code and play with code 문자 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bff8675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9881534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 35\n",
    "lr = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "string = \"understand with code and play with code!\"\n",
    "chars = \"abcdefghijklmnopqrstuvwxyz ?!.,:;01\"\n",
    "char_list = [i for i in chars]\n",
    "n_letters = len(char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a345fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_onehot(string):\n",
    "    start = np.zeros(shape=len(char_list), dtype=int)\n",
    "    end = np.zeros(shape=len(char_list), dtype=int)\n",
    "    start[-2] = 1\n",
    "    end[-1] = 1\n",
    "    for i in string:\n",
    "        idx = char_list.index(i)\n",
    "        zero = np.zeros(shape=n_letters, dtype=int)\n",
    "        zero[idx] =  1\n",
    "        start = np.vstack([start, zero])\n",
    "    output = np.vstack([start, end])\n",
    "    return output\n",
    "\n",
    "def onehot_to_word(onehot_1):\n",
    "    onehot = torch.Tensor.numpy(onehot_1)\n",
    "    return char_list[onehot.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2f3a6938",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size, hidden_size)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(hidden_size, output_size)\n",
    "        self.act_fn = nn.Tanh()\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        hidden = self.act_fn(self.i2h(input) + self.h2h(hidden))\n",
    "        output = self.i2o(hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "    \n",
    "rnn = RNN(n_letters, n_hidden, n_letters)\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "582612b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0043, grad_fn=<AddBackward0>)\n",
      "tensor(0.6112, grad_fn=<AddBackward0>)\n",
      "tensor(0.3155, grad_fn=<AddBackward0>)\n",
      "tensor(0.1775, grad_fn=<AddBackward0>)\n",
      "tensor(0.1099, grad_fn=<AddBackward0>)\n",
      "tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "tensor(0.0689, grad_fn=<AddBackward0>)\n",
      "tensor(0.0610, grad_fn=<AddBackward0>)\n",
      "tensor(0.0497, grad_fn=<AddBackward0>)\n",
      "tensor(0.0418, grad_fn=<AddBackward0>)\n",
      "tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "tensor(0.0417, grad_fn=<AddBackward0>)\n",
      "tensor(0.0368, grad_fn=<AddBackward0>)\n",
      "tensor(0.0338, grad_fn=<AddBackward0>)\n",
      "tensor(0.0319, grad_fn=<AddBackward0>)\n",
      "tensor(0.0382, grad_fn=<AddBackward0>)\n",
      "tensor(0.0325, grad_fn=<AddBackward0>)\n",
      "tensor(0.0307, grad_fn=<AddBackward0>)\n",
      "tensor(0.0302, grad_fn=<AddBackward0>)\n",
      "tensor(0.0307, grad_fn=<AddBackward0>)\n",
      "tensor(0.0295, grad_fn=<AddBackward0>)\n",
      "tensor(0.0290, grad_fn=<AddBackward0>)\n",
      "tensor(0.0469, grad_fn=<AddBackward0>)\n",
      "tensor(0.0339, grad_fn=<AddBackward0>)\n",
      "tensor(0.0309, grad_fn=<AddBackward0>)\n",
      "tensor(0.0297, grad_fn=<AddBackward0>)\n",
      "tensor(0.0293, grad_fn=<AddBackward0>)\n",
      "tensor(0.0290, grad_fn=<AddBackward0>)\n",
      "tensor(0.0289, grad_fn=<AddBackward0>)\n",
      "tensor(0.0288, grad_fn=<AddBackward0>)\n",
      "tensor(0.0287, grad_fn=<AddBackward0>)\n",
      "tensor(0.0286, grad_fn=<AddBackward0>)\n",
      "tensor(0.0286, grad_fn=<AddBackward0>)\n",
      "tensor(0.0285, grad_fn=<AddBackward0>)\n",
      "tensor(0.0288, grad_fn=<AddBackward0>)\n",
      "tensor(0.0285, grad_fn=<AddBackward0>)\n",
      "tensor(0.0283, grad_fn=<AddBackward0>)\n",
      "tensor(0.0349, grad_fn=<AddBackward0>)\n",
      "tensor(0.0304, grad_fn=<AddBackward0>)\n",
      "tensor(0.0291, grad_fn=<AddBackward0>)\n",
      "tensor(0.0287, grad_fn=<AddBackward0>)\n",
      "tensor(0.0284, grad_fn=<AddBackward0>)\n",
      "tensor(0.0283, grad_fn=<AddBackward0>)\n",
      "tensor(0.0282, grad_fn=<AddBackward0>)\n",
      "tensor(0.0280, grad_fn=<AddBackward0>)\n",
      "tensor(0.0277, grad_fn=<AddBackward0>)\n",
      "tensor(0.0325, grad_fn=<AddBackward0>)\n",
      "tensor(0.0286, grad_fn=<AddBackward0>)\n",
      "tensor(0.0352, grad_fn=<AddBackward0>)\n",
      "tensor(0.0295, grad_fn=<AddBackward0>)\n",
      "tensor(0.0279, grad_fn=<AddBackward0>)\n",
      "tensor(0.0270, grad_fn=<AddBackward0>)\n",
      "tensor(0.0361, grad_fn=<AddBackward0>)\n",
      "tensor(0.0313, grad_fn=<AddBackward0>)\n",
      "tensor(0.0290, grad_fn=<AddBackward0>)\n",
      "tensor(0.0256, grad_fn=<AddBackward0>)\n",
      "tensor(0.0471, grad_fn=<AddBackward0>)\n",
      "tensor(0.0321, grad_fn=<AddBackward0>)\n",
      "tensor(0.0276, grad_fn=<AddBackward0>)\n",
      "tensor(0.0243, grad_fn=<AddBackward0>)\n",
      "tensor(0.0251, grad_fn=<AddBackward0>)\n",
      "tensor(0.0232, grad_fn=<AddBackward0>)\n",
      "tensor(0.0231, grad_fn=<AddBackward0>)\n",
      "tensor(0.0182, grad_fn=<AddBackward0>)\n",
      "tensor(0.0126, grad_fn=<AddBackward0>)\n",
      "tensor(0.0156, grad_fn=<AddBackward0>)\n",
      "tensor(0.0098, grad_fn=<AddBackward0>)\n",
      "tensor(0.0071, grad_fn=<AddBackward0>)\n",
      "tensor(0.0115, grad_fn=<AddBackward0>)\n",
      "tensor(0.0068, grad_fn=<AddBackward0>)\n",
      "tensor(0.0044, grad_fn=<AddBackward0>)\n",
      "tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "tensor(0.0048, grad_fn=<AddBackward0>)\n",
      "tensor(0.0056, grad_fn=<AddBackward0>)\n",
      "tensor(0.0037, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "tensor(0.0036, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "# 문자열을 onehot 벡터로 만들고 이를 토치 텐서로 바꿔줍니다.\n",
    "# 또한 데이터타입도 학습에 맞게 바꿔줍니다.\n",
    "one_hot = torch.from_numpy(string_to_onehot(string)).type_as(torch.FloatTensor())\n",
    "\n",
    "for i in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    # 학습에 앞서 hidden state를 초기화해줍니다.\n",
    "    hidden = rnn.init_hidden()\n",
    "    \n",
    "    # 문자열 전체에 대한 손실을 구하기 위해 total_loss라는 변수를 만들어줍니다. \n",
    "    total_loss = 0\n",
    "    for j in range(one_hot.size()[0]-1):\n",
    "        # 입력은 앞에 글자 \n",
    "        input_ = one_hot[j:j+1,:]\n",
    "        # 목표값은 뒤에 글자\n",
    "        target = one_hot[j+1]\n",
    "        output, hidden = rnn.forward(input_, hidden)\n",
    "        \n",
    "        loss = loss_func(output.view(-1),target.view(-1))\n",
    "        total_loss += loss\n",
    "\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5056879f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "understand with code and play with code!\n"
     ]
    }
   ],
   "source": [
    "# test \n",
    "# hidden state 는 처음 한번만 초기화해줍니다.\n",
    "\n",
    "start = torch.zeros(1,n_letters)\n",
    "start[:,-2] = 1\n",
    "\n",
    "with torch.no_grad():\n",
    "    hidden = rnn.init_hidden()\n",
    "    # 처음 입력으로 start token을 전달해줍니다.\n",
    "    input_ = start\n",
    "    # output string에 문자들을 계속 붙여줍니다.\n",
    "    output_string = \"\"\n",
    "\n",
    "    # 원래는 end token이 나올때 까지 반복하는게 맞으나 끝나지 않아서 string의 길이로 정했습니다.\n",
    "    for i in range(len(string)):\n",
    "        output, hidden = rnn.forward(input_, hidden)\n",
    "        # 결과값을 문자로 바꿔서 output_string에 붙여줍니다.\n",
    "        output_string += onehot_to_word(output.data)\n",
    "        # 또한 이번의 결과값이 다음의 입력값이 됩니다.\n",
    "        input_ = output\n",
    "\n",
    "print(output_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5cd5a6",
   "metadata": {},
   "source": [
    "#### 100% 일치함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01122dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
